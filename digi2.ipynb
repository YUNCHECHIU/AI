{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 785)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "(33600, 784)\n",
      "[[ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]]\n",
      "(33600, 10)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from __future__ import print_function\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "from sklearn import preprocessing \n",
    "\n",
    "train1=pd.read_csv(\"train.csv\")\n",
    "print(train1.shape)\n",
    "test1 = pd.read_csv('test.csv')\n",
    "y_=train1.pop(\"label\")\n",
    "y1 = np.zeros((len(y_), 10))  \n",
    "y1[np.arange(len(y_)), y_] = 1\n",
    "\n",
    "\n",
    "\n",
    "train2=train1.values\n",
    "test2=test1.values\n",
    "print(type(train1))\n",
    "\n",
    "# type(train)\n",
    "train = train2/256\n",
    "test=test2/256\n",
    "print(type(train))\n",
    "# train = train2\n",
    "# test=test2\n",
    "\n",
    "# print(y1)\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(train,y1,test_size=0.2,random_state=1)\n",
    "\n",
    "print(type(y_train))\n",
    "print(X_train.shape)\n",
    "type(X_train)\n",
    "print(X_train)\n",
    "print(y_train.shape)\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1120\n"
     ]
    }
   ],
   "source": [
    "batch_size=30\n",
    "n_batch=len(X_train)//batch_size\n",
    "print(n_batch)\n",
    "# print(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##DNN\n",
    "# x=tf.placeholder(tf.float32,[None,784])\n",
    "# y=tf.placeholder(tf.float32,[None,10])\n",
    "\n",
    "# W=tf.Variable(tf.zeros([784,10]))\n",
    "# b=tf.Variable(tf.zeros([10]))\n",
    "# prediction=tf.nn.softmax(tf.matmul(x,W)+b)\n",
    "# loss=tf.reduce_mean(tf.square(y-prediction))\n",
    "# train_step=tf.train.GradientDescentOptimizer(0.2).minimize(loss)\n",
    "\n",
    "# init=tf.global_variables_initializer()\n",
    "# correct_prediction=tf.equal(tf.argmax(y,1),tf.argmax(prediction,1))\n",
    "# accuracy=tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "# ans=tf.argmax(prediction,1)\n",
    "\n",
    "# with tf.Session() as sess:\n",
    "#     sess.run(init)\n",
    "#     for epoch in range(21):\n",
    "#         for batch in range(n_batch):\n",
    "\n",
    "#             batch_idx_start = batch * batch_size\n",
    "#             batch_idx_stop = (batch+1) * batch_size  \n",
    "#             batch_xs,batch_ys=X_train[batch_idx_start : batch_idx_stop],y_train[batch_idx_start : batch_idx_stop] \n",
    "        \n",
    "#             sess.run(train_step,feed_dict={x:batch_xs,y:batch_ys})\n",
    "#         acc=sess.run(accuracy,feed_dict={x:X_test,y:y_test}) \n",
    "            \n",
    "            \n",
    "\n",
    "            \n",
    "#         print(\"Iter\" + str(epoch) + \",Testing Accuracy\" +str(acc)) \n",
    "\n",
    "#         anser=sess.run(ans,feed_dict={x:test})\n",
    "#         print(anser[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##DROP OUT\n",
    "# x=tf.placeholder(tf.float32,[None,784])\n",
    "# y=tf.placeholder(tf.float32,[None,10])\n",
    "# keep_prob=tf.placeholder(tf.float32)\n",
    "\n",
    "# W1=tf.Variable(tf.truncated_normal([784,2000],stddev=0.1))\n",
    "# b1=tf.Variable(tf.zeros([2000])+0.1)\n",
    "# L1=tf.nn.tanh(tf.matmul(x,W1)+b1)\n",
    "# L1_drop=tf.nn.dropout(L1,keep_prob)\n",
    "\n",
    "# W2=tf.Variable(tf.truncated_normal([2000,2000],stddev=0.1))\n",
    "# b2=tf.Variable(tf.zeros([2000])+0.1)\n",
    "# L2=tf.nn.tanh(tf.matmul(L1_drop,W2)+b2)\n",
    "# L2_drop=tf.nn.dropout(L2,keep_prob)\n",
    "\n",
    "# W3=tf.Variable(tf.truncated_normal([2000,1000],stddev=0.1))\n",
    "# b3=tf.Variable(tf.zeros([1000])+0.1)\n",
    "# L3=tf.nn.tanh(tf.matmul(L2_drop,W3)+b3)\n",
    "# L3_drop=tf.nn.dropout(L3,keep_prob)\n",
    "\n",
    "# W4=tf.Variable(tf.truncated_normal([1000,10],stddev=0.1))\n",
    "# b4=tf.Variable(tf.zeros([10])+0.1)\n",
    "\n",
    "# prediction=tf.nn.softmax(tf.matmul(L3_drop,W4)+b4)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# loss=tf.reduce_mean(tf.square(y-prediction))\n",
    "# train_step=tf.train.GradientDescentOptimizer(0.2).minimize(loss)\n",
    "\n",
    "# init=tf.global_variables_initializer()\n",
    "# correct_prediction=tf.equal(tf.argmax(y,1),tf.argmax(prediction,1))\n",
    "# accuracy=tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "# ans=tf.argmax(prediction,1)\n",
    "\n",
    "\n",
    "# with tf.Session() as sess:\n",
    "#     sess.run(init)\n",
    "\n",
    "#     for epoch in range(1201):\n",
    "#         for batch in range(n_batch):\n",
    "#             batch_idx_start = batch * batch_size\n",
    "#             batch_idx_stop = (batch+1) * batch_size  \n",
    "        \n",
    "\n",
    "\n",
    "#             batch_xs,batch_ys=X_train[batch_idx_start : batch_idx_stop],y_train[batch_idx_start : batch_idx_stop] \n",
    "#             sess.run(train_step,feed_dict={x:batch_xs,y:batch_ys,keep_prob:0.75})\n",
    "            \n",
    "#         test_acc=sess.run(accuracy,feed_dict={x:X_test,y:y_test,keep_prob:1.0})    \n",
    "#         train_acc=sess.run(accuracy,feed_dict={x:X_train,y:y_train,keep_prob:1.0})    \n",
    "        \n",
    "#         print(\"Iter\" + str(epoch) + \",Testing Accuracy\" +str(test_acc)+ \",Training Accuracy\" +str(train_acc))  \n",
    "       \n",
    "#         anser=sess.run(ans,feed_dict={x:test,keep_prob:1.0})      \n",
    "#         print(anser[0:10])\n",
    "    \n",
    "#         a=sess.run(prediction,feed_dict={x:X_train,keep_prob:1.0}) \n",
    "# #         print(a[0:10])\n",
    "#         b=sess.run(prediction,feed_dict={x:X_test,keep_prob:1.0}) \n",
    "#         c=sess.run(prediction,feed_dict={x:test,keep_prob:1.0})\n",
    "#     submission = pd.DataFrame({\n",
    "#         \"ImageId\": (test1.index+1),\n",
    "#         \"Label\": anser})\n",
    "\n",
    "#     submission.to_csv('submission1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #DNN OPT\n",
    "# x=tf.placeholder(tf.float32,[None,784])\n",
    "# y=tf.placeholder(tf.float32,[None,10])\n",
    "# keep_prob=tf.placeholder(tf.float32)\n",
    "# lr=tf.Variable(0.001,dtype=tf.float32)\n",
    "\n",
    "# W1=tf.Variable(tf.truncated_normal([784,500],stddev=0.1))\n",
    "# b1=tf.Variable(tf.zeros([500])+0.1)\n",
    "# L1=tf.nn.tanh(tf.matmul(x,W1)+b1)\n",
    "# L1_drop=tf.nn.dropout(L1,keep_prob)\n",
    "\n",
    "# W2=tf.Variable(tf.truncated_normal([500,300],stddev=0.1))\n",
    "# b2=tf.Variable(tf.zeros([300])+0.1)\n",
    "# L2=tf.nn.tanh(tf.matmul(L1_drop,W2)+b2)\n",
    "# L2_drop=tf.nn.dropout(L2,keep_prob)\n",
    "\n",
    "# W3=tf.Variable(tf.truncated_normal([300,10],stddev=0.1))\n",
    "# b3=tf.Variable(tf.zeros([10])+0.1)\n",
    "\n",
    "# prediction=tf.nn.softmax(tf.matmul(L2_drop,W3)+b3)\n",
    "\n",
    "\n",
    "# loss=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y,logits=prediction))\n",
    "# train_step=tf.train.AdamOptimizer(lr).minimize(loss)\n",
    "\n",
    "\n",
    "# init=tf.global_variables_initializer()\n",
    "# correct_prediction=tf.equal(tf.argmax(y,1),tf.argmax(prediction,1))\n",
    "# accuracy=tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "# ans=tf.argmax(prediction,1)\n",
    "\n",
    "\n",
    "# with tf.Session() as sess:\n",
    "#     sess.run(init)\n",
    "    \n",
    "#     for epoch in range(201):\n",
    "#         sess.run(tf.assign(lr,0.001*(0.95**epoch)))\n",
    "#         for batch in range(n_batch):\n",
    "#             batch_idx_start = batch * batch_size\n",
    "#             batch_idx_stop = (batch+1) * batch_size  \n",
    "        \n",
    "\n",
    "\n",
    "#             batch_xs,batch_ys=X_train[batch_idx_start : batch_idx_stop],y_train[batch_idx_start : batch_idx_stop] \n",
    "#             sess.run(train_step,feed_dict={x:batch_xs,y:batch_ys,keep_prob:0.7})\n",
    "            \n",
    "#         test_acc=sess.run(accuracy,feed_dict={x:X_test,y:y_test,keep_prob:1.0})    \n",
    "#         train_acc=sess.run(accuracy,feed_dict={x:X_train,y:y_train,keep_prob:1.0})    \n",
    "        \n",
    "#         print(\"Iter\" + str(epoch) + \",Testing Accuracy\" +str(test_acc)+ \",Training Accuracy\" +str(train_acc))  \n",
    "       \n",
    "#         anser=sess.run(ans,feed_dict={x:test,keep_prob:1.0})      \n",
    "#         print(anser[0:10])\n",
    "    \n",
    "#         a=sess.run(prediction,feed_dict={x:X_train,keep_prob:1.0}) \n",
    "# #         print(a[0:10])\n",
    "#         b=sess.run(prediction,feed_dict={x:X_test,keep_prob:1.0}) \n",
    "#         c=sess.run(prediction,feed_dict={x:test,keep_prob:1.0})\n",
    "#     submission = pd.DataFrame({\n",
    "#         \"ImageId\": (test1.index+1),\n",
    "#         \"Label\": anser})\n",
    "\n",
    "#     submission.to_csv('submission1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter0,Testing Accuracy0.94869\n",
      "Iter1,Testing Accuracy0.963929\n",
      "Iter2,Testing Accuracy0.968452\n",
      "Iter3,Testing Accuracy0.970238\n",
      "Iter4,Testing Accuracy0.972143\n",
      "Iter5,Testing Accuracy0.974881\n",
      "Iter6,Testing Accuracy0.977262\n",
      "Iter7,Testing Accuracy0.978452\n",
      "Iter8,Testing Accuracy0.979167\n",
      "Iter9,Testing Accuracy0.980476\n",
      "Iter10,Testing Accuracy0.980595\n",
      "Iter11,Testing Accuracy0.981071\n",
      "Iter12,Testing Accuracy0.982143\n",
      "Iter13,Testing Accuracy0.9825\n",
      "Iter14,Testing Accuracy0.982976\n",
      "Iter15,Testing Accuracy0.983691\n",
      "Iter16,Testing Accuracy0.984524\n",
      "Iter17,Testing Accuracy0.985595\n",
      "Iter18,Testing Accuracy0.986548\n",
      "Iter19,Testing Accuracy0.987143\n",
      "Iter20,Testing Accuracy0.987857\n",
      "Iter21,Testing Accuracy0.987976\n",
      "Iter22,Testing Accuracy0.988095\n",
      "Iter23,Testing Accuracy0.988095\n",
      "Iter24,Testing Accuracy0.988333\n",
      "Iter25,Testing Accuracy0.988571\n",
      "Iter26,Testing Accuracy0.988452\n",
      "Iter27,Testing Accuracy0.988214\n",
      "Iter28,Testing Accuracy0.988095\n",
      "Iter29,Testing Accuracy0.987976\n",
      "Iter30,Testing Accuracy0.987976\n",
      "Iter31,Testing Accuracy0.987857\n",
      "Iter32,Testing Accuracy0.988095\n",
      "Iter33,Testing Accuracy0.988095\n",
      "Iter34,Testing Accuracy0.987976\n",
      "Iter35,Testing Accuracy0.988095\n",
      "Iter36,Testing Accuracy0.987976\n",
      "Iter37,Testing Accuracy0.987738\n",
      "Iter38,Testing Accuracy0.988095\n",
      "Iter39,Testing Accuracy0.988333\n",
      "Iter40,Testing Accuracy0.988452\n",
      "Iter41,Testing Accuracy0.988452\n",
      "Iter42,Testing Accuracy0.988571\n",
      "Iter43,Testing Accuracy0.988571\n",
      "Iter44,Testing Accuracy0.988571\n",
      "Iter45,Testing Accuracy0.988571\n",
      "Iter46,Testing Accuracy0.988929\n",
      "Iter47,Testing Accuracy0.98869\n",
      "Iter48,Testing Accuracy0.989048\n",
      "Iter49,Testing Accuracy0.98881\n",
      "Iter50,Testing Accuracy0.988929\n",
      "Iter51,Testing Accuracy0.98869\n",
      "Iter52,Testing Accuracy0.98881\n",
      "Iter53,Testing Accuracy0.98881\n",
      "Iter54,Testing Accuracy0.98881\n",
      "Iter55,Testing Accuracy0.989048\n",
      "Iter56,Testing Accuracy0.988929\n",
      "Iter57,Testing Accuracy0.989048\n",
      "Iter58,Testing Accuracy0.989286\n",
      "Iter59,Testing Accuracy0.989167\n",
      "Iter60,Testing Accuracy0.989167\n",
      "Iter61,Testing Accuracy0.989048\n",
      "Iter62,Testing Accuracy0.989286\n",
      "Iter63,Testing Accuracy0.989405\n",
      "Iter64,Testing Accuracy0.989405\n",
      "Iter65,Testing Accuracy0.989286\n",
      "Iter66,Testing Accuracy0.989286\n",
      "Iter67,Testing Accuracy0.989643\n",
      "Iter68,Testing Accuracy0.989524\n",
      "Iter69,Testing Accuracy0.989643\n",
      "Iter70,Testing Accuracy0.989048\n",
      "Iter71,Testing Accuracy0.989643\n",
      "Iter72,Testing Accuracy0.989643\n",
      "Iter73,Testing Accuracy0.99\n",
      "Iter74,Testing Accuracy0.989881\n",
      "Iter75,Testing Accuracy0.99\n",
      "Iter76,Testing Accuracy0.99\n",
      "Iter77,Testing Accuracy0.99\n",
      "Iter78,Testing Accuracy0.99\n",
      "Iter79,Testing Accuracy0.99\n",
      "Iter80,Testing Accuracy0.990119\n",
      "Iter81,Testing Accuracy0.990119\n",
      "Iter82,Testing Accuracy0.99\n",
      "Iter83,Testing Accuracy0.99\n",
      "Iter84,Testing Accuracy0.990119\n",
      "Iter85,Testing Accuracy0.990119\n",
      "Iter86,Testing Accuracy0.990119\n",
      "Iter87,Testing Accuracy0.990238\n",
      "Iter88,Testing Accuracy0.990238\n",
      "Iter89,Testing Accuracy0.990238\n",
      "Iter90,Testing Accuracy0.990238\n",
      "Iter91,Testing Accuracy0.990119\n",
      "Iter92,Testing Accuracy0.990357\n",
      "Iter93,Testing Accuracy0.990119\n",
      "Iter94,Testing Accuracy0.990238\n",
      "Iter95,Testing Accuracy0.990357\n",
      "Iter96,Testing Accuracy0.990238\n",
      "Iter97,Testing Accuracy0.990238\n",
      "Iter98,Testing Accuracy0.990357\n",
      "Iter99,Testing Accuracy0.990238\n",
      "Iter100,Testing Accuracy0.990357\n",
      "Iter101,Testing Accuracy0.990357\n",
      "Iter102,Testing Accuracy0.990119\n",
      "Iter103,Testing Accuracy0.990357\n",
      "Iter104,Testing Accuracy0.990119\n",
      "Iter105,Testing Accuracy0.990238\n",
      "Iter106,Testing Accuracy0.990119\n",
      "Iter107,Testing Accuracy0.990119\n",
      "Iter108,Testing Accuracy0.989762\n",
      "Iter109,Testing Accuracy0.99\n",
      "Iter110,Testing Accuracy0.99\n",
      "Iter111,Testing Accuracy0.99\n",
      "Iter112,Testing Accuracy0.99\n",
      "Iter113,Testing Accuracy0.990357\n",
      "Iter114,Testing Accuracy0.990238\n",
      "Iter115,Testing Accuracy0.990238\n",
      "Iter116,Testing Accuracy0.990119\n",
      "Iter117,Testing Accuracy0.990238\n",
      "Iter118,Testing Accuracy0.99\n",
      "Iter119,Testing Accuracy0.989881\n",
      "Iter120,Testing Accuracy0.99\n",
      "Iter121,Testing Accuracy0.99\n",
      "Iter122,Testing Accuracy0.989881\n",
      "Iter123,Testing Accuracy0.99\n",
      "Iter124,Testing Accuracy0.989762\n",
      "Iter125,Testing Accuracy0.989881\n",
      "Iter126,Testing Accuracy0.989762\n",
      "Iter127,Testing Accuracy0.989881\n",
      "Iter128,Testing Accuracy0.989524\n",
      "Iter129,Testing Accuracy0.989762\n",
      "Iter130,Testing Accuracy0.989643\n",
      "Iter131,Testing Accuracy0.989643\n",
      "Iter132,Testing Accuracy0.989762\n",
      "Iter133,Testing Accuracy0.989643\n",
      "Iter134,Testing Accuracy0.989643\n",
      "Iter135,Testing Accuracy0.989762\n",
      "Iter136,Testing Accuracy0.989643\n",
      "Iter137,Testing Accuracy0.989524\n",
      "Iter138,Testing Accuracy0.989643\n",
      "Iter139,Testing Accuracy0.989405\n",
      "Iter140,Testing Accuracy0.989762\n",
      "Iter141,Testing Accuracy0.989643\n",
      "Iter142,Testing Accuracy0.989762\n",
      "Iter143,Testing Accuracy0.989643\n",
      "Iter144,Testing Accuracy0.989643\n",
      "Iter145,Testing Accuracy0.989524\n",
      "Iter146,Testing Accuracy0.989643\n",
      "Iter147,Testing Accuracy0.989762\n",
      "Iter148,Testing Accuracy0.989524\n",
      "Iter149,Testing Accuracy0.989524\n",
      "Iter150,Testing Accuracy0.989286\n",
      "Iter151,Testing Accuracy0.989405\n",
      "Iter152,Testing Accuracy0.989405\n",
      "Iter153,Testing Accuracy0.989405\n",
      "Iter154,Testing Accuracy0.989405\n",
      "Iter155,Testing Accuracy0.989524\n",
      "Iter156,Testing Accuracy0.989524\n",
      "Iter157,Testing Accuracy0.989643\n",
      "Iter158,Testing Accuracy0.989762\n",
      "Iter159,Testing Accuracy0.989524\n",
      "Iter160,Testing Accuracy0.989643\n",
      "Iter161,Testing Accuracy0.989643\n",
      "Iter162,Testing Accuracy0.989881\n",
      "Iter163,Testing Accuracy0.989762\n",
      "Iter164,Testing Accuracy0.989881\n",
      "Iter165,Testing Accuracy0.989286\n",
      "Iter166,Testing Accuracy0.989524\n",
      "Iter167,Testing Accuracy0.989524\n",
      "Iter168,Testing Accuracy0.99\n",
      "Iter169,Testing Accuracy0.989762\n",
      "Iter170,Testing Accuracy0.989643\n",
      "Iter171,Testing Accuracy0.989762\n",
      "Iter172,Testing Accuracy0.989643\n",
      "Iter173,Testing Accuracy0.989881\n",
      "Iter174,Testing Accuracy0.989881\n",
      "Iter175,Testing Accuracy0.990119\n",
      "Iter176,Testing Accuracy0.99\n",
      "Iter177,Testing Accuracy0.990238\n",
      "Iter178,Testing Accuracy0.990238\n",
      "Iter179,Testing Accuracy0.990238\n",
      "Iter180,Testing Accuracy0.990476\n",
      "Iter181,Testing Accuracy0.990357\n",
      "Iter182,Testing Accuracy0.990476\n",
      "Iter183,Testing Accuracy0.990238\n",
      "Iter184,Testing Accuracy0.990476\n",
      "Iter185,Testing Accuracy0.990357\n",
      "Iter186,Testing Accuracy0.989881\n",
      "Iter187,Testing Accuracy0.989762\n",
      "Iter188,Testing Accuracy0.989881\n",
      "Iter189,Testing Accuracy0.989762\n",
      "Iter190,Testing Accuracy0.990119\n",
      "Iter191,Testing Accuracy0.989762\n",
      "Iter192,Testing Accuracy0.989762\n",
      "Iter193,Testing Accuracy0.989881\n",
      "Iter194,Testing Accuracy0.989881\n",
      "Iter195,Testing Accuracy0.989762\n",
      "Iter196,Testing Accuracy0.990238\n",
      "Iter197,Testing Accuracy0.990357\n",
      "Iter198,Testing Accuracy0.990238\n",
      "Iter199,Testing Accuracy0.99\n",
      "Iter200,Testing Accuracy0.99\n",
      "Iter201,Testing Accuracy0.99\n",
      "Iter202,Testing Accuracy0.989643\n",
      "Iter203,Testing Accuracy0.989762\n",
      "Iter204,Testing Accuracy0.990238\n",
      "Iter205,Testing Accuracy0.990119\n",
      "Iter206,Testing Accuracy0.990238\n",
      "Iter207,Testing Accuracy0.99\n",
      "Iter208,Testing Accuracy0.989881\n",
      "Iter209,Testing Accuracy0.990119\n",
      "Iter210,Testing Accuracy0.990238\n",
      "Iter211,Testing Accuracy0.990238\n",
      "Iter212,Testing Accuracy0.990238\n",
      "Iter213,Testing Accuracy0.990119\n",
      "Iter214,Testing Accuracy0.99\n",
      "Iter215,Testing Accuracy0.99\n",
      "Iter216,Testing Accuracy0.989762\n",
      "Iter217,Testing Accuracy0.989881\n",
      "Iter218,Testing Accuracy0.989881\n",
      "Iter219,Testing Accuracy0.989881\n",
      "Iter220,Testing Accuracy0.989881\n",
      "Iter221,Testing Accuracy0.989762\n",
      "Iter222,Testing Accuracy0.989881\n",
      "Iter223,Testing Accuracy0.99\n",
      "Iter224,Testing Accuracy0.989762\n",
      "Iter225,Testing Accuracy0.990238\n",
      "Iter226,Testing Accuracy0.990119\n",
      "Iter227,Testing Accuracy0.989643\n",
      "Iter228,Testing Accuracy0.989881\n",
      "Iter229,Testing Accuracy0.989881\n",
      "Iter230,Testing Accuracy0.989762\n",
      "Iter231,Testing Accuracy0.989762\n",
      "Iter232,Testing Accuracy0.989762\n",
      "Iter233,Testing Accuracy0.989524\n",
      "Iter234,Testing Accuracy0.989881\n",
      "Iter235,Testing Accuracy0.989524\n",
      "Iter236,Testing Accuracy0.99\n",
      "Iter237,Testing Accuracy0.989405\n",
      "Iter238,Testing Accuracy0.989643\n",
      "Iter239,Testing Accuracy0.989405\n",
      "Iter240,Testing Accuracy0.989524\n",
      "Iter241,Testing Accuracy0.989762\n",
      "Iter242,Testing Accuracy0.989524\n",
      "Iter243,Testing Accuracy0.989524\n",
      "Iter244,Testing Accuracy0.989762\n",
      "Iter245,Testing Accuracy0.989524\n",
      "Iter246,Testing Accuracy0.989643\n",
      "Iter247,Testing Accuracy0.989643\n",
      "Iter248,Testing Accuracy0.989643\n",
      "Iter249,Testing Accuracy0.989762\n",
      "Iter250,Testing Accuracy0.989881\n",
      "Iter251,Testing Accuracy0.989643\n",
      "Iter252,Testing Accuracy0.989524\n",
      "Iter253,Testing Accuracy0.989405\n",
      "Iter254,Testing Accuracy0.989643\n",
      "Iter255,Testing Accuracy0.989643\n",
      "Iter256,Testing Accuracy0.990119\n",
      "Iter257,Testing Accuracy0.989286\n",
      "Iter258,Testing Accuracy0.989405\n",
      "Iter259,Testing Accuracy0.989405\n",
      "Iter260,Testing Accuracy0.989524\n",
      "Iter261,Testing Accuracy0.989524\n",
      "Iter262,Testing Accuracy0.989405\n",
      "Iter263,Testing Accuracy0.989286\n",
      "Iter264,Testing Accuracy0.989286\n",
      "Iter265,Testing Accuracy0.989167\n",
      "Iter266,Testing Accuracy0.989405\n",
      "Iter267,Testing Accuracy0.989405\n",
      "Iter268,Testing Accuracy0.989286\n",
      "Iter269,Testing Accuracy0.989405\n",
      "Iter270,Testing Accuracy0.989524\n",
      "Iter271,Testing Accuracy0.989643\n",
      "Iter272,Testing Accuracy0.989286\n",
      "Iter273,Testing Accuracy0.989524\n",
      "Iter274,Testing Accuracy0.989286\n",
      "Iter275,Testing Accuracy0.989643\n",
      "Iter276,Testing Accuracy0.989524\n",
      "Iter277,Testing Accuracy0.989643\n",
      "Iter278,Testing Accuracy0.989762\n",
      "Iter279,Testing Accuracy0.989762\n",
      "Iter280,Testing Accuracy0.99\n",
      "Iter281,Testing Accuracy0.989762\n",
      "Iter282,Testing Accuracy0.989762\n",
      "Iter283,Testing Accuracy0.989524\n",
      "Iter284,Testing Accuracy0.990119\n",
      "Iter285,Testing Accuracy0.990238\n",
      "Iter286,Testing Accuracy0.99\n",
      "Iter287,Testing Accuracy0.99\n",
      "Iter288,Testing Accuracy0.990119\n",
      "Iter289,Testing Accuracy0.989881\n",
      "Iter290,Testing Accuracy0.989762\n",
      "Iter291,Testing Accuracy0.989881\n",
      "Iter292,Testing Accuracy0.99\n",
      "Iter293,Testing Accuracy0.99\n",
      "Iter294,Testing Accuracy0.989881\n",
      "Iter295,Testing Accuracy0.989881\n",
      "Iter296,Testing Accuracy0.99\n",
      "Iter297,Testing Accuracy0.989762\n",
      "Iter298,Testing Accuracy0.99\n",
      "Iter299,Testing Accuracy0.989881\n",
      "Iter300,Testing Accuracy0.989881\n",
      "Iter301,Testing Accuracy0.989762\n",
      "Iter302,Testing Accuracy0.989524\n",
      "Iter303,Testing Accuracy0.989881\n",
      "Iter304,Testing Accuracy0.989643\n",
      "Iter305,Testing Accuracy0.989643\n",
      "Iter306,Testing Accuracy0.989643\n",
      "Iter307,Testing Accuracy0.989643\n",
      "Iter308,Testing Accuracy0.989762\n",
      "Iter309,Testing Accuracy0.989524\n",
      "Iter310,Testing Accuracy0.989762\n",
      "Iter311,Testing Accuracy0.989643\n",
      "Iter312,Testing Accuracy0.989524\n",
      "Iter313,Testing Accuracy0.989762\n",
      "Iter314,Testing Accuracy0.989762\n",
      "Iter315,Testing Accuracy0.989643\n",
      "Iter316,Testing Accuracy0.989643\n",
      "Iter317,Testing Accuracy0.989881\n",
      "Iter318,Testing Accuracy0.989762\n",
      "Iter319,Testing Accuracy0.989762\n",
      "Iter320,Testing Accuracy0.989762\n",
      "Iter321,Testing Accuracy0.989762\n",
      "Iter322,Testing Accuracy0.990119\n",
      "Iter323,Testing Accuracy0.99\n",
      "Iter324,Testing Accuracy0.989762\n",
      "Iter325,Testing Accuracy0.989762\n",
      "Iter326,Testing Accuracy0.989643\n",
      "Iter327,Testing Accuracy0.989881\n",
      "Iter328,Testing Accuracy0.989881\n",
      "Iter329,Testing Accuracy0.989881\n",
      "Iter330,Testing Accuracy0.989881\n",
      "Iter331,Testing Accuracy0.989762\n",
      "Iter332,Testing Accuracy0.989881\n",
      "Iter333,Testing Accuracy0.989881\n",
      "Iter334,Testing Accuracy0.989881\n",
      "Iter335,Testing Accuracy0.989881\n",
      "Iter336,Testing Accuracy0.989881\n",
      "Iter337,Testing Accuracy0.989762\n",
      "Iter338,Testing Accuracy0.989762\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-d9df590f972b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0mbatch_xs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_ys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_idx_start\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mbatch_idx_stop\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_idx_start\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mbatch_idx_stop\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m             \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbatch_xs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbatch_ys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkeep_prob\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m0.7\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0mtest_acc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkeep_prob\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#CNN\n",
    "\n",
    "def weight_variable(shape):\n",
    "    initial=tf.truncated_normal(shape,stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial=tf.constant(0.1,shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def conv2d(x,W):\n",
    "    return tf.nn.conv2d(x,W,strides=[1,1,1,1],padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x,ksize=[1,2,2,1],strides=[1,2,2,1],padding='SAME')\n",
    "\n",
    "x=tf.placeholder(tf.float32,[None,784])\n",
    "y=tf.placeholder(tf.float32,[None,10])\n",
    "\n",
    "x_image=tf.reshape(x,[-1,28,28,1])\n",
    "\n",
    "W_conv1=weight_variable([3,3,1,32])\n",
    "b_conv1=bias_variable([32])\n",
    "\n",
    "h_conv1=tf.nn.tanh(conv2d(x_image,W_conv1)+b_conv1)\n",
    "h_pool1=max_pool_2x2(h_conv1)\n",
    "\n",
    "W_conv2=weight_variable([3,3,32,64])\n",
    "b_conv2=bias_variable([64])\n",
    "\n",
    "h_conv2=tf.nn.tanh(conv2d(h_pool1,W_conv2)+b_conv2)\n",
    "h_pool2=max_pool_2x2(h_conv2)\n",
    "\n",
    "W_conv3=weight_variable([3,3,64,64])\n",
    "b_conv3=bias_variable([64])\n",
    "\n",
    "h_conv3=tf.nn.tanh(conv2d(h_pool2,W_conv3)+b_conv3)\n",
    "h_pool3=max_pool_2x2(h_conv3)\n",
    "\n",
    "W_conv4=weight_variable([3,3,64,64])\n",
    "b_conv4=bias_variable([64])\n",
    "\n",
    "h_conv4=tf.nn.tanh(conv2d(h_pool3,W_conv4)+b_conv4)\n",
    "h_pool4=max_pool_2x2(h_conv4)\n",
    "\n",
    "W_fcl=weight_variable([2*2*64,2048])\n",
    "b_fcl=bias_variable([2048])\n",
    "\n",
    "h_pool4_flat=tf.reshape(h_pool4,[-1,2*2*64])\n",
    "h_fcl=tf.nn.tanh(tf.matmul(h_pool4_flat,W_fcl)+b_fcl)\n",
    "\n",
    "keep_prob=tf.placeholder(tf.float32)\n",
    "h_fc1_drop=tf.nn.dropout(h_fcl,keep_prob)\n",
    "\n",
    "W_fc2=weight_variable([2048,10])\n",
    "b_fc2=bias_variable([10])\n",
    "\n",
    "l2_loss = tf.nn.l2_loss(W_fcl)+ tf.nn.l2_loss(W_fc2)\n",
    "\n",
    "prediction=tf.nn.softmax(tf.matmul(h_fc1_drop,W_fc2)+b_fc2)\n",
    "\n",
    "cross_entropy=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y,logits=prediction))+ 0.01 * l2_loss\n",
    "train_step=tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "correct_prediction=tf.equal(tf.argmax(y,1),tf.argmax(prediction,1))\n",
    "accuracy=tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "ans=tf.argmax(prediction,1)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for epoch in range(401):\n",
    "        for batch in range(n_batch):\n",
    "            batch_idx_start = batch * batch_size\n",
    "            batch_idx_stop = (batch+1) * batch_size  \n",
    "        \n",
    "\n",
    "\n",
    "            batch_xs,batch_ys=X_train[batch_idx_start : batch_idx_stop],y_train[batch_idx_start : batch_idx_stop] \n",
    "            sess.run(train_step,feed_dict={x:batch_xs,y:batch_ys,keep_prob:0.7})\n",
    "            \n",
    "        test_acc=sess.run(accuracy,feed_dict={x:X_test,y:y_test,keep_prob:1.0})    \n",
    "        \n",
    "        \n",
    "        print(\"Iter\" + str(epoch) + \",Testing Accuracy\" +str(test_acc))  \n",
    "       \n",
    "        anser=sess.run(ans,feed_dict={x:test,keep_prob:1.0}) \n",
    "\n",
    "\n",
    "        submission = pd.DataFrame({\n",
    "        \"ImageId\": (test1.index+1),\n",
    "        \"Label\": anser})\n",
    "\n",
    "    submission.to_csv('submission.csv', index=False)\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # amin, amax = a.min(), a.max() # 求最大最小值\n",
    "# # a1 = (a-amin)/(amax-amin) # (矩阵元素-最小值)/(最大值-最小值)\n",
    "\n",
    "# # bmin, bmax = b.min(), b.max() # 求最大最小值\n",
    "# # b1 = (b-bmin)/(bmax-bmin) # (矩阵元素-最小值)/(最大值-最小值)\n",
    "\n",
    "# # a1=np.log10(a)\n",
    "# # b1=np.log10(b)\n",
    "\n",
    "# # a1 = preprocessing.scale(a)\n",
    "# # b1 = preprocessing.scale(b)\n",
    "\n",
    "# # a1=-np.log10(a)\n",
    "# # b1=-np.log10(b)\n",
    "# # c1=-np.log10(c)\n",
    "\n",
    "# # print(a1[0])\n",
    "\n",
    "# X_train,X_test,y_train,y_test=train_test_split(train1,y_,test_size=0.2,random_state=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# C=np.concatenate((X_train,a),axis=1)\n",
    "# D=np.concatenate((X_test,b),axis=1)\n",
    "# E=np.concatenate((test1,c),axis=1)\n",
    "\n",
    "\n",
    "# # clf = XGBClassifier()\n",
    "# clf=RandomForestClassifier(random_state=1, n_estimators=100, min_samples_split=2,min_samples_leaf=1)\n",
    "# # clf=tree.DecisionTreeClassifier(max_depth=160000,random_state=42)\n",
    "\n",
    "# clf.fit(C,y_train)\n",
    "\n",
    "# predictions=clf.predict(D)\n",
    "# print (accuracy_score(y_test,predictions))\n",
    "\n",
    "# clf1=RandomForestClassifier(random_state=1, n_estimators=100, min_samples_split=2,min_samples_leaf=1)\n",
    "# # clf1=tree.DecisionTreeClassifier(max_depth=160000,random_state=42)\n",
    "\n",
    "# clf1.fit(X_train,y_train)\n",
    "\n",
    "# predictions1=clf1.predict(X_test)\n",
    "# print (accuracy_score(y_test,predictions1))\n",
    "\n",
    "# pre = clf.predict(E)\n",
    "\n",
    "# submission = pd.DataFrame({\n",
    "#         \"ImageId\": (test1.index+1),\n",
    "#         \"Label\": pre\n",
    "#     })\n",
    "\n",
    "# submission.to_csv('submission.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LSTM\n",
    "\n",
    "\n",
    "# n_inputs=28\n",
    "# max_time=28\n",
    "# lstm_size=3200\n",
    "# n_classes=10\n",
    "# # batch_size=50\n",
    "# # n_batch=mnist.train.num_examples//batch_size\n",
    "\n",
    "# x=tf.placeholder(tf.float32,[None,784])\n",
    "# y=tf.placeholder(tf.float32,[None,10])\n",
    "\n",
    "# weights=tf.Variable(tf.truncated_normal([lstm_size,n_classes],stddev=0.1))\n",
    "# biases=tf.Variable(tf.constant(0.1,shape=[n_classes]))\n",
    "\n",
    "# def RNN(X,weights,biases):\n",
    "#     inputs=tf.reshape(X,[-1,max_time,n_inputs])\n",
    "#     lstm_cell=tf.contrib.rnn.LSTMCell(lstm_size)\n",
    "#     outputs,final_state=tf.nn.dynamic_rnn(lstm_cell,inputs,dtype=tf.float32)\n",
    "#     results=tf.nn.softmax(tf.matmul(final_state[1],weights)+biases)\n",
    "#     return results\n",
    "    \n",
    "\n",
    "# prediction=RNN(x,weights,biases)\n",
    "\n",
    "# cross_entropy=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y,logits=prediction))\n",
    "# train_step=tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "# correct_prediction=tf.equal(tf.argmax(y,1),tf.argmax(prediction,1))\n",
    "# accuracy=tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "# init=tf.global_variables_initializer()\n",
    "# ans=tf.argmax(prediction,1)\n",
    "\n",
    "# with tf.Session() as sess:\n",
    "#     sess.run(init)\n",
    "# #     for epoch in range(6):\n",
    "# #         for batch in range(n_batch):\n",
    "# #             batch_xs,batch_ys=mnist.train.next_batch(batch_size)\n",
    "# #             sess.run(train_step,feed_dict={x:batch_xs,y:batch_ys})\n",
    "         \n",
    "# #         acc=sess.run(accuracy,feed_dict={x:mnist.test.images,y:mnist.test.labels})    \n",
    "# # #         train_acc=sess.run(accuracy,feed_dict={x:mnist.train.images,y:mnist.train.labels,keep_prob:1.0})    \n",
    "# #         print(\"Iter\" + str(epoch) + \",Testing Accuracy\" +str(acc)) \n",
    "    \n",
    "#     for epoch in range(252):\n",
    "#         for batch in range(n_batch):\n",
    "#             batch_idx_start = batch * batch_size\n",
    "#             batch_idx_stop = (batch+1) * batch_size  \n",
    "        \n",
    "\n",
    "\n",
    "#             batch_xs,batch_ys=X_train[batch_idx_start : batch_idx_stop],y_train[batch_idx_start : batch_idx_stop] \n",
    "#             sess.run(train_step,feed_dict={x:batch_xs,y:batch_ys})\n",
    "            \n",
    "#         acc=sess.run(accuracy,feed_dict={x:X_test,y:y_test})    \n",
    "        \n",
    "        \n",
    "#         print(\"Iter\" + str(epoch) + \",Testing Accuracy\" +str(acc))  \n",
    "       \n",
    "#         anser=sess.run(ans,feed_dict={x:test}) \n",
    "\n",
    "#         submission = pd.DataFrame({\n",
    "#         \"ImageId\": (test1.index+1),\n",
    "#         \"Label\": anser})\n",
    "\n",
    "#     submission.to_csv('submission.csv', index=False)    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
