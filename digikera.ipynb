{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from __future__ import print_function\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "from sklearn import preprocessing \n",
    "\n",
    "import cv2\n",
    "import skimage.io as io\n",
    "\n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization, GlobalAveragePooling2D\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(42000, 28, 28, 1)\n",
      "(28000, 28, 28, 1)\n",
      "(42000, 10)\n"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "train1=pd.read_csv(\"train.csv\")\n",
    "# print(train1.shape)\n",
    "test1 = pd.read_csv('test.csv')\n",
    "# print(test2.shape)\n",
    "\n",
    "y_=train1.pop(\"label\")\n",
    "y1 = np.zeros((len(y_), 10))  \n",
    "y1[np.arange(len(y_)), y_] = 1\n",
    "\n",
    "train2=train1.values\n",
    "train2 = train2/255\n",
    "train2=train2.reshape((42000,28,28))\n",
    "train2=np.expand_dims(train2,axis=-1)\n",
    "\n",
    "test2=test1.values\n",
    "test2 = test2/255\n",
    "test2=test2.reshape((28000,28,28))\n",
    "test=np.expand_dims(test2,axis=-1)\n",
    "\n",
    "\n",
    "\n",
    "print(type(train2))\n",
    "print(train2.shape)\n",
    "print(test.shape)\n",
    "print(y1.shape)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_valid,y_train,y_valid=train_test_split(train2,y1,test_size=0.2,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            (None, 28, 28, 64)        640       \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 28, 28, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 28, 28, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 14, 14, 256)       295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 14, 14, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 14, 14, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 7, 7, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 7, 7, 256)         590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 7, 7, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 7, 7, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 3, 3, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 3, 3, 256)         590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 3, 3, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 3, 3, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 1, 1, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                1290      \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 10)                40        \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,588,402\n",
      "Trainable params: 1,586,206\n",
      "Non-trainable params: 2,196\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model_name = 'classic_CNN'\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same', input_shape=X_train.shape[1:]))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(activation='relu'))\n",
    "model.add(MaxPooling2D((1, 1)))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(Conv2D(256, (3, 3), padding='same', activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(Conv2D(256, (3, 3), padding='same', activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(Conv2D(256, (3, 3), padding='same', activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(128))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(activation='relu'))\n",
    "\n",
    "model.add(Dense(10))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(activation='softmax'))\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "2098/2100 [============================>.] - ETA: 0s - loss: 1.6423 - acc: 0.4707\n",
      "Epoch 00001: val_loss improved from inf to 0.82665, saving model to ./saved_models/classic_CNN.h5\n",
      "2100/2100 [==============================] - 41s 20ms/step - loss: 1.6418 - acc: 0.4710 - val_loss: 0.8266 - val_acc: 0.8283\n",
      "Epoch 2/25\n",
      "2099/2100 [============================>.] - ETA: 0s - loss: 1.1358 - acc: 0.7018\n",
      "Epoch 00002: val_loss improved from 0.82665 to 0.61789, saving model to ./saved_models/classic_CNN.h5\n",
      "2100/2100 [==============================] - 40s 19ms/step - loss: 1.1358 - acc: 0.7018 - val_loss: 0.6179 - val_acc: 0.8957\n",
      "Epoch 3/25\n",
      "2098/2100 [============================>.] - ETA: 0s - loss: 0.9777 - acc: 0.7677\n",
      "Epoch 00003: val_loss improved from 0.61789 to 0.52190, saving model to ./saved_models/classic_CNN.h5\n",
      "2100/2100 [==============================] - 41s 19ms/step - loss: 0.9777 - acc: 0.7678 - val_loss: 0.5219 - val_acc: 0.9256\n",
      "Epoch 4/25\n",
      "2098/2100 [============================>.] - ETA: 0s - loss: 0.8879 - acc: 0.8014\n",
      "Epoch 00004: val_loss improved from 0.52190 to 0.44463, saving model to ./saved_models/classic_CNN.h5\n",
      "2100/2100 [==============================] - 40s 19ms/step - loss: 0.8878 - acc: 0.8015 - val_loss: 0.4446 - val_acc: 0.9446\n",
      "Epoch 5/25\n",
      "2097/2100 [============================>.] - ETA: 0s - loss: 0.8292 - acc: 0.8220\n",
      "Epoch 00005: val_loss improved from 0.44463 to 0.41440, saving model to ./saved_models/classic_CNN.h5\n",
      "2100/2100 [==============================] - 40s 19ms/step - loss: 0.8292 - acc: 0.8220 - val_loss: 0.4144 - val_acc: 0.9536\n",
      "Epoch 6/25\n",
      "2098/2100 [============================>.] - ETA: 0s - loss: 0.7897 - acc: 0.8331\n",
      "Epoch 00006: val_loss improved from 0.41440 to 0.36543, saving model to ./saved_models/classic_CNN.h5\n",
      "2100/2100 [==============================] - 40s 19ms/step - loss: 0.7899 - acc: 0.8329 - val_loss: 0.3654 - val_acc: 0.9599\n",
      "Epoch 7/25\n",
      "2098/2100 [============================>.] - ETA: 0s - loss: 0.7507 - acc: 0.8466\n",
      "Epoch 00007: val_loss improved from 0.36543 to 0.33706, saving model to ./saved_models/classic_CNN.h5\n",
      "2100/2100 [==============================] - 40s 19ms/step - loss: 0.7506 - acc: 0.8466 - val_loss: 0.3371 - val_acc: 0.9663\n",
      "Epoch 8/25\n",
      "2097/2100 [============================>.] - ETA: 0s - loss: 0.7267 - acc: 0.8559\n",
      "Epoch 00008: val_loss improved from 0.33706 to 0.33483, saving model to ./saved_models/classic_CNN.h5\n",
      "2100/2100 [==============================] - 40s 19ms/step - loss: 0.7266 - acc: 0.8559 - val_loss: 0.3348 - val_acc: 0.9690\n",
      "Epoch 9/25\n",
      "2096/2100 [============================>.] - ETA: 0s - loss: 0.7063 - acc: 0.8593\n",
      "Epoch 00009: val_loss improved from 0.33483 to 0.29531, saving model to ./saved_models/classic_CNN.h5\n",
      "2100/2100 [==============================] - 40s 19ms/step - loss: 0.7061 - acc: 0.8594 - val_loss: 0.2953 - val_acc: 0.9731\n",
      "Epoch 10/25\n",
      "2098/2100 [============================>.] - ETA: 0s - loss: 0.6844 - acc: 0.8649\n",
      "Epoch 00010: val_loss did not improve\n",
      "2100/2100 [==============================] - 39s 19ms/step - loss: 0.6843 - acc: 0.8650 - val_loss: 0.3020 - val_acc: 0.9731\n",
      "Epoch 11/25\n",
      "2099/2100 [============================>.] - ETA: 0s - loss: 0.6591 - acc: 0.8723\n",
      "Epoch 00011: val_loss improved from 0.29531 to 0.27973, saving model to ./saved_models/classic_CNN.h5\n",
      "2100/2100 [==============================] - 40s 19ms/step - loss: 0.6590 - acc: 0.8723 - val_loss: 0.2797 - val_acc: 0.9750\n",
      "Epoch 12/25\n",
      "2098/2100 [============================>.] - ETA: 0s - loss: 0.6466 - acc: 0.8758\n",
      "Epoch 00012: val_loss improved from 0.27973 to 0.25635, saving model to ./saved_models/classic_CNN.h5\n",
      "2100/2100 [==============================] - 40s 19ms/step - loss: 0.6465 - acc: 0.8758 - val_loss: 0.2564 - val_acc: 0.9767\n",
      "Epoch 13/25\n",
      "2098/2100 [============================>.] - ETA: 0s - loss: 0.6297 - acc: 0.8783\n",
      "Epoch 00013: val_loss improved from 0.25635 to 0.25062, saving model to ./saved_models/classic_CNN.h5\n",
      "2100/2100 [==============================] - 40s 19ms/step - loss: 0.6297 - acc: 0.8784 - val_loss: 0.2506 - val_acc: 0.9776\n",
      "Epoch 14/25\n",
      "2097/2100 [============================>.] - ETA: 0s - loss: 0.6161 - acc: 0.8817\n",
      "Epoch 00014: val_loss improved from 0.25062 to 0.23899, saving model to ./saved_models/classic_CNN.h5\n",
      "2100/2100 [==============================] - 40s 19ms/step - loss: 0.6162 - acc: 0.8816 - val_loss: 0.2390 - val_acc: 0.9787\n",
      "Epoch 15/25\n",
      "2097/2100 [============================>.] - ETA: 0s - loss: 0.6051 - acc: 0.8886\n",
      "Epoch 00015: val_loss improved from 0.23899 to 0.22929, saving model to ./saved_models/classic_CNN.h5\n",
      "2100/2100 [==============================] - 40s 19ms/step - loss: 0.6048 - acc: 0.8887 - val_loss: 0.2293 - val_acc: 0.9790\n",
      "Epoch 16/25\n",
      "2097/2100 [============================>.] - ETA: 0s - loss: 0.5860 - acc: 0.8934\n",
      "Epoch 00016: val_loss improved from 0.22929 to 0.22143, saving model to ./saved_models/classic_CNN.h5\n",
      "2100/2100 [==============================] - 40s 19ms/step - loss: 0.5860 - acc: 0.8933 - val_loss: 0.2214 - val_acc: 0.9790\n",
      "Epoch 17/25\n",
      "2097/2100 [============================>.] - ETA: 0s - loss: 0.5702 - acc: 0.8995\n",
      "Epoch 00017: val_loss improved from 0.22143 to 0.21777, saving model to ./saved_models/classic_CNN.h5\n",
      "2100/2100 [==============================] - 40s 19ms/step - loss: 0.5701 - acc: 0.8995 - val_loss: 0.2178 - val_acc: 0.9807\n",
      "Epoch 18/25\n",
      "2098/2100 [============================>.] - ETA: 0s - loss: 0.5683 - acc: 0.8984\n",
      "Epoch 00018: val_loss improved from 0.21777 to 0.21308, saving model to ./saved_models/classic_CNN.h5\n",
      "2100/2100 [==============================] - 40s 19ms/step - loss: 0.5681 - acc: 0.8985 - val_loss: 0.2131 - val_acc: 0.9808\n",
      "Epoch 19/25\n",
      "2098/2100 [============================>.] - ETA: 0s - loss: 0.5545 - acc: 0.9028\n",
      "Epoch 00019: val_loss improved from 0.21308 to 0.21118, saving model to ./saved_models/classic_CNN.h5\n",
      "2100/2100 [==============================] - 40s 19ms/step - loss: 0.5547 - acc: 0.9027 - val_loss: 0.2112 - val_acc: 0.9792\n",
      "Epoch 20/25\n",
      "2099/2100 [============================>.] - ETA: 0s - loss: 0.5442 - acc: 0.9053\n",
      "Epoch 00020: val_loss improved from 0.21118 to 0.20515, saving model to ./saved_models/classic_CNN.h5\n",
      "2100/2100 [==============================] - 40s 19ms/step - loss: 0.5442 - acc: 0.9053 - val_loss: 0.2051 - val_acc: 0.9805\n",
      "Epoch 21/25\n",
      "2099/2100 [============================>.] - ETA: 0s - loss: 0.5350 - acc: 0.9087"
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=10,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='constant',\n",
    "    cval=0)\n",
    "\n",
    "optimizer = keras.optimizers.Adam(lr=10e-6)\n",
    "\n",
    "model_path = './saved_models/{}.h5'.format(model_name)\n",
    "checkpoint = ModelCheckpoint(model_path, monitor='val_loss', save_best_only=True, verbose=1)\n",
    "earlystop = EarlyStopping(monitor='val_loss', patience=10, verbose=1)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizer, metrics=['accuracy'])\n",
    "# Fit the model on the batches generated by datagen.flow().\n",
    "batch_size = 16\n",
    "aug_ratio = 1\n",
    "epochs = 25\n",
    "steps_per_epoch = int(aug_ratio * X_train.shape[0] / batch_size)\n",
    "validation_steps = int(aug_ratio * X_valid.shape[0] / batch_size)\n",
    "model_history = model.fit_generator(datagen.flow(X_train, y_train, batch_size = batch_size),\n",
    "                                    epochs = epochs,\n",
    "                                    validation_data = (X_valid, y_valid),\n",
    "                                    callbacks = [checkpoint, earlystop],\n",
    "                                    steps_per_epoch=steps_per_epoch,\n",
    "                                    validation_steps=validation_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_loss = model_history.history['loss']\n",
    "val_loss = model_history.history['val_loss']\n",
    "\n",
    "plt.plot(training_loss, label=\"training_loss\")\n",
    "plt.plot(val_loss, label=\"validation_loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Learning Curve\")\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_acc = model_history.history['acc']\n",
    "val_acc = model_history.history['val_acc']\n",
    "\n",
    "plt.plot(training_acc, label=\"training_acc\")\n",
    "plt.plot(val_acc, label=\"validation_acc\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Acc\")\n",
    "plt.title(\"Learning Curve\")\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test, X_id = load_test_data()\n",
    "# test1 = pd.read_csv('/data/examples/may_the_4_be_with_u/where_am_i/img-submission.csv')\n",
    "\n",
    "model_path = './saved_models/{}.h5'.format(model_name)\n",
    "model = load_model(model_path)\n",
    "\n",
    "scores = model.evaluate(X_valid, y_valid, verbose=1)\n",
    "print('Validation loss:', scores[0])\n",
    "print('Validation accuracy:', scores[1])\n",
    "\n",
    "y_test_pred = model.predict_classes(test)\n",
    "y_test_pred_df = pd.DataFrame({'ImageId': np.array(test1.index+1), 'Label':y_test_pred})\n",
    "y_test_pred_df.to_csv('./submissions/{}.csv'.format(model_name), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
